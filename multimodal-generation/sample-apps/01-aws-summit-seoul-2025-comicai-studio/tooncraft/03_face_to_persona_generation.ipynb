{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Automatically install required packages\"\"\"\n",
    "    packages = [\n",
    "        'boto3>=1.26.0',\n",
    "        'requests>=2.26.0',\n",
    "        'requests-aws4auth>=1.3.0',\n",
    "        'pillow==11.2.1',\n",
    "        # 'ipython==8.30.0'\n",
    "    ]\n",
    "    \n",
    "    print(\"üì¶ Installing required packages...\")\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "            print(f\"‚úÖ {package} installed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to install {package}: {e}\")\n",
    "    \n",
    "    print(\"\\nüéâ Package installation complete! Run the next cell.\")\n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from bedrock_text import BedrockText\n",
    "from bedrock_image import BedrockAmazonImage, NovaImageSize\n",
    "from bedrock_video import BedrockAmazonVideo, VideoStatus\n",
    "from bedrock_model import BedrockModel\n",
    "from image_utils import (\n",
    "    get_image_bytes_from_file,\n",
    "    bytes_to_base64,\n",
    "    display_image,\n",
    "    display_image_bytes,\n",
    "    display_video_bytes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Declare required models, classes, variables, and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_REGION = \"us-east-1\"\n",
    "S3_VIDEO_BUCKET = \"<your-bucket-name>\" # Replace with you S3 bucket name\n",
    "    \n",
    "# (Required) face image path\n",
    "SAMPLE_IMAGE_PATH = \"./img/sample_face.png\"\n",
    "SAMPLE_IMAGE_FORMAT = \"png\"\n",
    "\n",
    "if S3_VIDEO_BUCKET == \"<your-bucket-name>\":\n",
    "    print(\"‚ö†Ô∏è WARNING: Please update the 'S3_VIDEO_BUCKET' with your actual S3 bucket name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM model\n",
    "bedrock_llm = BedrockText(modelId=BedrockModel.NOVA_LITE_CR, region=AWS_REGION)\n",
    "\n",
    "# Image model\n",
    "bedrock_image = BedrockAmazonImage(region=AWS_REGION, modelId=BedrockModel.NOVA_CANVAS)\n",
    "\n",
    "# Video model\n",
    "bedrock_video = BedrockAmazonVideo(\n",
    "    region=AWS_REGION,\n",
    "    modelId=BedrockModel.NOVA_REEL,\n",
    "    bucket_name=S3_VIDEO_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample image\n",
    "img_bytes = get_image_bytes_from_file(file_path=SAMPLE_IMAGE_PATH, format=SAMPLE_IMAGE_FORMAT)\n",
    "display_image_bytes(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(str):\n",
    "    try:\n",
    "        str = str.replace('```json', '').replace('```', '')\n",
    "        return json.loads(str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract character personas and episodes from image (Nova Lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"You are an empathetic AI storyteller who infers mood and personality from a person's face to create a lighthearted story based on everyday life.\n",
    "\n",
    "## Instruction\n",
    "\n",
    "1. Analyze the person's gender, age range, impression, and personality based on the image.\n",
    "2. Define the persona of the individual, reflecting their character and possible profession.\n",
    "3. Based on the inferred gender, age, personality, and profession, write a playful or funny short episode. Make it trendy and cheerful, and limit it to a maximum of 2 sentences.\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Please provide your description in the following format, without any additional explanation:\n",
    "{{\n",
    "    \"persona\": \"1‚Äì2 sentence summary describing gender, age range, impression, personality, and profession\",\n",
    "    \"episode\": \"A playful and trendy short episode, maximum two sentences\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "res = bedrock_llm.converse_output(text=PROMPT, image=img_bytes, format=SAMPLE_IMAGE_FORMAT)\n",
    "j = extract_json(res)\n",
    "persona = j.get('persona', '')\n",
    "episode = j.get('episode', '')\n",
    "\n",
    "print(persona)\n",
    "print(episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate a Image Prompt (Nova Lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"You are a professional prompt engineer specializing in image generation models.\n",
    "Based on the given image, create a prompt that preserves the subject's facial features as accurately as possible, while vividly visualizing the scene described below.\n",
    "Emphasize the context of the episode clearly, but ensure the character's appearance remains consistent.\n",
    "\n",
    "- persona: {persona}\n",
    "- episode: {episode}\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Please provide your description in the following format, without any additional explanation:\n",
    "{{\n",
    "    \"prompt\": \"A single English sentence for image generation, clearly describing the character‚Äôs features and the scene.\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "res = bedrock_llm.converse_output(text=PROMPT)\n",
    "prompt = json.loads(res).get('prompt', '')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate a character using an image and generated prompts (Nova Canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64 = bytes_to_base64(img_bytes)\n",
    "width, height = NovaImageSize.SIZE_1280x720.value\n",
    "cfgScale = 9.0\n",
    "similarity = 0.9\n",
    "seed = 512\n",
    "\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"IMAGE_VARIATION\",\n",
    "    \"imageVariationParams\": {\n",
    "        \"images\": [image_base64],\n",
    "        \"similarityStrength\": similarity,\n",
    "        \"text\": f\"{prompt}, cartoon style, colorful digital illustration\",\n",
    "        \"negativeText\": \"ugly, deformed, low quality, blurry, text\"\n",
    "    },\n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"cfgScale\": cfgScale,\n",
    "        \"seed\": seed\n",
    "    }\n",
    "})\n",
    "\n",
    "img = bedrock_image.generate_image(body)\n",
    "display_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate a video prompt (Nova Lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"You are a prompt engineer specializing in crafting prompts for image-to-video generation.\n",
    "Refer to the given image and image description to write a dynamic, high-quality video generation prompt in English\n",
    "\n",
    "## Image Description\n",
    "{prompt}\n",
    "\n",
    "## Instruction\n",
    "Video generation models work best with descriptive prompts rather than command-based instructions. When crafting prompts, focus on what you want to see rather than telling the model what to do. Think of writing a detailed caption or scene description like you‚Äôre explaining a video that already exists. For example, describing elements like the main subjects, what they‚Äôre doing, the setting around them, how the scene is lit, the overall artistic style, and any camera movements can help create more accurate results. The key is to paint a complete picture through description rather than giving step-by-step directions. This means instead of saying ‚Äúcreate a dramatic scene,‚Äù you could describe ‚Äúa stormy beach at sunset with crashing waves and dark clouds, filmed with a slow aerial shot moving over the coastline.‚Äù The more specific and descriptive you can be about the visual elements you want, the better the output will be. You might want to include details about the subject, action, environment, lighting, style, and camera motion.\n",
    "\n",
    "When writing a video generation prompt for Nova Reel, be mindful of the following requirements and best practices:\n",
    "\n",
    "Prompts must be no longer than 500 characters.\n",
    "For best results, place camera movement descriptions at the start or end of your prompt.\n",
    "Specify what you want to include rather than what to exclude. For example, instead of ‚Äúfruit basket with no bananas,‚Äù say ‚Äúfruit basket with apples, oranges, and pears.‚Äù\n",
    "When describing camera movements in your video prompts, be specific about the type of motion you want‚Äîwhether it‚Äôs a smooth dolly shot (moving forward/backward), a pan (sweeping left/right), or a tilt (moving up/down). For more dynamic effects, you can request aerial shots, orbit movements, or specialized techniques like dolly zooms. You can also specify the speed of the movement\n",
    "\n",
    "## Example\n",
    "- Track right shot of single red balloon floating through empty subway tunnel. Balloon glows from within, casting soft red light on concrete walls. Cinematic 4k, moody lighting\n",
    "- Dolly in shot of peaceful deer drinking from forest stream. Sunlight filtering through and bokeh of other deer and forest plants. 4k cinematic.\n",
    "- Orbit shot of crystal light bulb centered on polished marble surface, gentle floating gears spinning inside with golden glow. Premium lighting. 4k cinematic.\n",
    "- Pedestal down in a pan in modern kitchen penne pasta with heavy cream white sauce on top, mushrooms and garlic, steam coming out.\n",
    "- Orbit shot of premium over-ear headphones on a reflective surface. Dramatic side lighting accentuates the curves and edges, casting subtle shadows that highlight the product‚Äôs premium build quality.\n",
    "\n",
    "## Output format\n",
    "\n",
    "Please provide your description in the following format, without any additional explanation:\n",
    "{{\n",
    "    \"video_prompt\": \"Video generation prompt in English\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "res = bedrock_llm.converse_output(text=PROMPT)\n",
    "video_prompt = json.loads(res).get('video_prompt', '')\n",
    "print(video_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate a single-shot video from image and text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_arn = bedrock_video.generate_video(\n",
    "    text=video_prompt,\n",
    "    image=img[0],\n",
    "    imageFormat=\"png\",\n",
    "    durationSeconds=6,\n",
    "    fps=24,\n",
    "    dimension=\"1280x720\"\n",
    ")\n",
    "\n",
    "status, s3Uri, invocation = bedrock_video.query_job(invocation_arn)\n",
    "\n",
    "while status == VideoStatus.IN_PROGRESS:\n",
    "    time.sleep(30)\n",
    "    status, s3Uri, invocation = bedrock_video.query_job(invocation_arn)\n",
    "\n",
    "video = bedrock_video.get_video(invocation_arn=invocation_arn)\n",
    "display_video_bytes(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate a multi-shot video from text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_arn = bedrock_video.generate_multishot_video(\n",
    "    text=video_prompt,\n",
    "    durationSeconds=24,\n",
    "    fps=24,\n",
    "    dimension=\"1280x720\"\n",
    ")\n",
    "\n",
    "status, s3Uri, invocation = bedrock_video.query_job(invocation_arn)\n",
    "\n",
    "while status == VideoStatus.IN_PROGRESS:\n",
    "    time.sleep(30)\n",
    "    status, s3Uri, invocation = bedrock_video.query_job(invocation_arn)\n",
    "\n",
    "video = bedrock_video.get_video(invocation_arn=invocation_arn)\n",
    "display_video_bytes(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
